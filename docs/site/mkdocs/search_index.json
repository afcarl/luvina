{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to Luvina\n\n\nLuvina is a high-level Natural Language Processing API for Python built on top of spaCy and NLTK. It was developed with the idea of creating easy-to-use pre-processing functionalities.\n\n\nInstallation\n\n\nYou can install luvina from PyPI by running:\n\n\npip install luvina",
            "title": "Home"
        },
        {
            "location": "/#welcome-to-luvina",
            "text": "Luvina is a high-level Natural Language Processing API for Python built on top of spaCy and NLTK. It was developed with the idea of creating easy-to-use pre-processing functionalities.",
            "title": "Welcome to Luvina"
        },
        {
            "location": "/#installation",
            "text": "You can install luvina from PyPI by running:  pip install luvina",
            "title": "Installation"
        },
        {
            "location": "/backend/",
            "text": "Luvina backends\n\n\nLuvina does not handle low level functionalities by itself; instead, it relies on already optimized libraries:\n\n\nLuvina currently supports functionalities from two backends:\n\n\n\n\nspaCy\n is an Industrial-strength Natural Language Processing (NLP) with Python and Cython\n\n\nNLTK\n is a Python library with easy-to-use interfaces and suite of text-processing libraries.",
            "title": "Backend"
        },
        {
            "location": "/backend/#luvina-backends",
            "text": "Luvina does not handle low level functionalities by itself; instead, it relies on already optimized libraries:  Luvina currently supports functionalities from two backends:   spaCy  is an Industrial-strength Natural Language Processing (NLP) with Python and Cython  NLTK  is a Python library with easy-to-use interfaces and suite of text-processing libraries.",
            "title": "Luvina backends"
        },
        {
            "location": "/functions/",
            "text": "Core functions\n\n\nTokenization\n\n\nluvina.backend.tokenize(sentence, lowercase=True)\n\n\n\n\nJust your basic tokenization operation.\n\n\nluv.tokenize('The cat sat on the mat.')\n>>> ['the', 'cat', 'sat', 'on', 'the', 'mat', '.']\n\n\n\n\nDefinitions\n\n\nGet definitions from token using WordNet.\n\n\nluvina.backend.get_definition(token)\n\n\n\n\nluv.get_definition('car')\n>>> 'a motor vehicle with four wheels; usually propelled by an internal combustion engine'\n\n\n\n\nSynonyms\n\n\nluvina.backend.get_synonyms(token)\n\n\n\n\nGet synonyms of the given token using WordNet.\n\n\nluv.get_synonyms('wallet')\n>>> ['billfold', 'notecase', 'pocketbook']\n\n\n\n\nStop words\n\n\nluvina.backend.get_stop_words(language='english'):\n\n\n\n\nGet a set of stop words (most common words) in the given language.\n\n\nlist(luv.get_stop_words())[:5]\n>>> ['doing', 'than', 'up', 'wouldn', 'this']\n\n\n\n\nCalculate WordNet similarity\n\n\nluvina.backend.calculate_wordnet_similarity(token_1, token_2):\n\n\n\n\nReturns a score based on the shortest path between the senses in the is-a (hypernym/hypnoym) taxonomy.\n\n\nluv.calculate_wordnet_similarity('dog','cat')\n>>> 0.8571428571428571\n\n\n\n\nLemmatize\n\n\nluvina.backend.lemmatize(token, pos='n'):\n\n\n\n\nBasic lemmatization using a given part-of-speech.\n\n\nluv.lemmatize('driving', pos='v')\n>>> 'drive'\n\n\n\n\nExpanding contractions\n\n\nluvina.backend.expand_contractions(sentence):\n\n\n\n\nExpand English contractions found in sentence/token:\n\n\nluv.expand_contractions(\"don't eat it\")\n>>> 'do not eat it'\n\n\n\n\nPOS tagging\n\n\nluvina.backend.tag_pos(tokens):\n\n\n\n\nPOS tagging using a pre-trained neural network from NLTK.\n\n\nluv.tag_pos(luv.tokenize('a person is driving'))\n>>> [('a', 'DT'), ('person', 'NN'), ('is', 'VBZ'), ('driving', 'VBG')]\n\n\n\n\nLevenshtein distance\n\n\nluvina.backend.calculate_levenshtein_distance(token_1, token_2):\n\n\n\n\nReturns number of characters that need to be substituted, inserted or deleted from \"token_1\" to get \"token_2\".\n\n\nluv.calculate_levenshtein_distance('base','vase')\n>>> 1",
            "title": "Functions"
        },
        {
            "location": "/functions/#core-functions",
            "text": "",
            "title": "Core functions"
        },
        {
            "location": "/functions/#tokenization",
            "text": "luvina.backend.tokenize(sentence, lowercase=True)  Just your basic tokenization operation.  luv.tokenize('The cat sat on the mat.')\n>>> ['the', 'cat', 'sat', 'on', 'the', 'mat', '.']",
            "title": "Tokenization"
        },
        {
            "location": "/functions/#definitions",
            "text": "Get definitions from token using WordNet.  luvina.backend.get_definition(token)  luv.get_definition('car')\n>>> 'a motor vehicle with four wheels; usually propelled by an internal combustion engine'",
            "title": "Definitions"
        },
        {
            "location": "/functions/#synonyms",
            "text": "luvina.backend.get_synonyms(token)  Get synonyms of the given token using WordNet.  luv.get_synonyms('wallet')\n>>> ['billfold', 'notecase', 'pocketbook']",
            "title": "Synonyms"
        },
        {
            "location": "/functions/#stop-words",
            "text": "luvina.backend.get_stop_words(language='english'):  Get a set of stop words (most common words) in the given language.  list(luv.get_stop_words())[:5]\n>>> ['doing', 'than', 'up', 'wouldn', 'this']",
            "title": "Stop words"
        },
        {
            "location": "/functions/#calculate-wordnet-similarity",
            "text": "luvina.backend.calculate_wordnet_similarity(token_1, token_2):  Returns a score based on the shortest path between the senses in the is-a (hypernym/hypnoym) taxonomy.  luv.calculate_wordnet_similarity('dog','cat')\n>>> 0.8571428571428571",
            "title": "Calculate WordNet similarity"
        },
        {
            "location": "/functions/#lemmatize",
            "text": "luvina.backend.lemmatize(token, pos='n'):  Basic lemmatization using a given part-of-speech.  luv.lemmatize('driving', pos='v')\n>>> 'drive'",
            "title": "Lemmatize"
        },
        {
            "location": "/functions/#expanding-contractions",
            "text": "luvina.backend.expand_contractions(sentence):  Expand English contractions found in sentence/token:  luv.expand_contractions(\"don't eat it\")\n>>> 'do not eat it'",
            "title": "Expanding contractions"
        },
        {
            "location": "/functions/#pos-tagging",
            "text": "luvina.backend.tag_pos(tokens):  POS tagging using a pre-trained neural network from NLTK.  luv.tag_pos(luv.tokenize('a person is driving'))\n>>> [('a', 'DT'), ('person', 'NN'), ('is', 'VBZ'), ('driving', 'VBG')]",
            "title": "POS tagging"
        },
        {
            "location": "/functions/#levenshtein-distance",
            "text": "luvina.backend.calculate_levenshtein_distance(token_1, token_2):  Returns number of characters that need to be substituted, inserted or deleted from \"token_1\" to get \"token_2\".  luv.calculate_levenshtein_distance('base','vase')\n>>> 1",
            "title": "Levenshtein distance"
        }
    ]
}